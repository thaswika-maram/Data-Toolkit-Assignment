{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99134187",
   "metadata": {},
   "source": [
    "# Theory questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282376b4",
   "metadata": {},
   "source": [
    "1. What is NumPy, and why is it widely used in Python\n",
    "\n",
    "- NumPy (short for Numerical Python) is a powerful open-source library in Python that provides support for:\n",
    "\n",
    "    - Large, multi-dimensional arrays and matrices\n",
    "\n",
    "    - A vast collection of mathematical functions to operate efficiently on these arrays\n",
    "- NumPy is essential for data science, machine learning, scientific research, and any field requiring heavy numerical computations in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdc82f",
   "metadata": {},
   "source": [
    "2. How does broadcasting work in NumPy\n",
    "\n",
    "- Broadcasting allows NumPy to perform arithmetic operations on arrays of different shapes by automatically “stretching” the smaller array along the missing dimensions so they have compatible shapes.\n",
    "\n",
    "- It helps avoid explicit loops and lets you write fast, clean code.\n",
    "\n",
    "- Broadcasting Rules (simplified):\n",
    "- NumPy compares the shapes of the two arrays starting from the trailing (rightmost) dimensions and works backward:\n",
    "\n",
    "    - If the dimensions are equal, or\n",
    "\n",
    "    - If one of the dimensions is 1,\n",
    "\n",
    "then the arrays are compatible for broadcasting along that dimension.\n",
    "\n",
    "- If these conditions aren’t met, NumPy raises a ValueError.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334b510",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "3. What is a Pandas DataFrame\n",
    "\n",
    "- A Pandas DataFrame is one of the most important data structures provided by the Pandas library in Python. It’s like a table or spreadsheet in memory, designed for working with structured data.\n",
    "- Key Features of a Pandas DataFrame:\n",
    "    - 2-dimensional labeled data structure\n",
    "(rows and columns, both can have labels/indexes)\n",
    "\n",
    "    - Columns can be of different data types (integers, floats, strings, etc.)\n",
    "\n",
    "    - Supports fast, flexible data manipulation, including filtering, aggregation, joining, reshaping, and more\n",
    "\n",
    "    - Built on top of NumPy arrays, combining efficient numerical operations with flexible data handling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d44312",
   "metadata": {},
   "source": [
    "4. Explain the use of the groupby() method in Pandas\n",
    "\n",
    "- The groupby() method is used to split a DataFrame into groups based on one or more keys (columns), then apply a function (like aggregation, transformation, or filtering) to each group independently, and finally combine the results.\n",
    "- groupby('Department') splits the data into groups: HR, IT, Finance.\n",
    "\n",
    "- ['Salary'].mean() computes the average salary in each group.\n",
    "\n",
    "- The result is a Series with the group names as index and the mean salary as values.\n",
    "- groupby() helps summarize or transform data based on categories.\n",
    "\n",
    "- It’s fundamental for data analysis tasks like reporting, segmentation, and data exploration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9c043",
   "metadata": {},
   "source": [
    "5. Why is Seaborn preferred for statistical visualizations\n",
    "\n",
    "- Seaborn is preferred for statistical visualizations because it is:\n",
    "\n",
    "- 1. Built on Top of Matplotlib\n",
    "Seaborn simplifies complex plotting commands from Matplotlib and provides high-level functions for common statistical tasks.\n",
    "\n",
    "2. Easier to Use for Statistical Plots\n",
    "It has built-in support for creating plots like:\n",
    "\n",
    "Box plots\n",
    "\n",
    "Violin plots\n",
    "\n",
    "Swarm plots\n",
    "\n",
    "Regression plots\n",
    "\n",
    "Heatmaps (e.g., correlation matrices)\n",
    "\n",
    "These are useful for analyzing distribution, relationships, and comparisons in data.\n",
    "\n",
    "3. Beautiful and Informative Defaults\n",
    "Seaborn comes with aesthetic default themes and color palettes, which make plots visually appealing and easier to interpret.\n",
    "\n",
    "4. Integrates Well with Pandas\n",
    "Seaborn works smoothly with Pandas DataFrames and can use column names directly, which makes it efficient for data exploration and analysis.\n",
    "\n",
    "5. Built-in Support for Aggregation and Statistical Estimation\n",
    "It can automatically perform operations like mean, standard deviation, and confidence intervals, making it perfect for summarizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db35d32d",
   "metadata": {},
   "source": [
    "6. What are the differences between NumPy arrays and Python lists\n",
    "\n",
    "- NumPy arrays and Python lists are both used to store collections of data, but they have significant differences. A key distinction is that NumPy arrays are homogeneous, meaning all elements must be of the same data type, whereas Python lists are heterogeneous, allowing elements of different types. NumPy arrays are more memory-efficient and offer faster performance, as they are implemented in C and optimized for numerical computations. They support vectorized operations, enabling element-wise computations without explicit loops, which makes them ideal for scientific and mathematical tasks. In contrast, Python lists require loops or list comprehensions for such operations, which can be slower. Additionally, NumPy arrays support multi-dimensional structures, making them suitable for handling matrices or large datasets. Overall, NumPy arrays are preferred in data science and machine learning applications, while Python lists are more suited for general-purpose programming.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480533fe",
   "metadata": {},
   "source": [
    "7. What is a heatmap, and when should it be used?\n",
    "\n",
    "- A heatmap is a data visualization technique that uses color gradients to represent the magnitude or intensity of data values in a two-dimensional space. Typically, it displays a matrix-like structure where each cell’s color reflects a numerical value, making it easy to identify patterns, correlations, or anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d6185",
   "metadata": {},
   "source": [
    "8. What does the term “vectorized operation” mean in NumPy\n",
    "\n",
    "- The term “vectorized operation” in NumPy refers to performing operations on entire arrays (vectors, matrices, etc.) at once, without using explicit loops.\n",
    "\n",
    "- Instead of iterating element by element (as in standard Python), NumPy performs operations using highly optimized C code under the hood, which makes it faster and more concise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c5a22",
   "metadata": {},
   "source": [
    "9. How does Matplotlib differ from Plotly\n",
    "\n",
    "- Matplotlib and Plotly are both powerful Python libraries for data visualization, but they differ significantly in their approach and features. Matplotlib is primarily used for creating static, publication-quality plots and is known for its flexibility and fine-grained customization. However, it requires more code to produce complex visuals and lacks built-in interactivity. On the other hand, Plotly specializes in creating interactive plots with features like zooming, tooltips, and dynamic updates built in by default. It is ideal for web applications, dashboards, and presentations. While Matplotlib is preferred in academic and research settings for producing static images, Plotly is widely used in data analysis and business intelligence for interactive data exploration. Ultimately, the choice depends on whether you need static precision or dynamic interaction in your visualizations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b1cad",
   "metadata": {},
   "source": [
    "10. What is the significance of hierarchical indexing in Pandas\n",
    "- Hierarchical indexing (also called MultiIndexing) in Pandas is a powerful feature that allows you to have multiple levels of indexing on a single axis (rows or columns). This enables you to work with higher-dimensional data in a 2D DataFrame or 1D Series, making it easier to organize, group, and access complex datasets.\n",
    "\n",
    "-  Significance of Hierarchical Indexing:\n",
    "Represents multi-dimensional data compactly\n",
    "\n",
    "It allows data with multiple keys (like \"State\" and \"City\") to be stored in a clean and structured way within a 2D DataFrame.\n",
    "\n",
    "Simplifies complex data analysis\n",
    "\n",
    "You can easily perform grouping, reshaping (e.g., stack, unstack), and aggregation operations.\n",
    "\n",
    "Improves data organization\n",
    "\n",
    "It adds clarity and hierarchy to data that naturally has multiple levels, such as time-series data with Year and Month, or Company and Department.\n",
    "\n",
    "Powerful slicing and subsetting\n",
    "\n",
    "You can use tuple-based indexing to slice data across multiple levels.\n",
    "\n",
    "Useful in pivot tables and grouped operations\n",
    "\n",
    "Hierarchical indexing is automatically created during operations like groupby() or pivot_table().\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce385aa",
   "metadata": {},
   "source": [
    "11. What is the role of Seaborn’s pairplot() function\n",
    "\n",
    "\n",
    "- The **pairplot()** function in Seaborn is used to create a grid of scatter plots for visualizing relationships between all pairs of numerical features in a dataset. It also shows the distribution of individual features on the diagonal using histograms or KDE plots.\n",
    "\n",
    "Exploratory Data Analysis (EDA):\n",
    "Helps in quickly identifying patterns, trends, and relationships between variables.\n",
    "\n",
    "Visualizing Correlation:\n",
    "You can visually assess how strongly variables are related — linear, non-linear, or no relationship.\n",
    "\n",
    "Multivariate Visualization:\n",
    "It shows every pairwise combination in a single, easy-to-interpret grid.\n",
    "\n",
    "Class-wise Analysis:\n",
    "When a hue parameter is specified (like a class label), it differentiates the plots by color, helping to understand how different classes are distributed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9d296",
   "metadata": {},
   "source": [
    "12. What is the purpose of the describe() function in Pandas\n",
    "\n",
    "- The describe() function in Pandas is used to generate summary statistics of a DataFrame or Series, providing a quick overview of the distribution and key properties of the data. It typically includes metrics such as count, mean, standard deviation, minimum, quartiles (25%, 50%, 75%), and maximum values for each numerical column. This helps in understanding the central tendency, spread, and range of the data, which is essential during exploratory data analysis (EDA). Additionally, when applied to categorical data, describe() provides counts of unique values, the most frequent value (top), and its frequency. Overall, describe() is a convenient and fast way to get insights into the data’s basic characteristics before deeper analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d4ca2",
   "metadata": {},
   "source": [
    "13. Why is handling missing data important in Pandas\n",
    "\n",
    "- Handling missing data in Pandas is important because missing or incomplete data can lead to inaccurate analyses, biased results, and errors in computations. Many data processing and statistical methods assume complete datasets, so ignoring missing values might cause algorithms to fail or produce misleading outputs. Properly dealing with missing data—whether by filling, interpolating, or removing it—ensures the integrity and reliability of your analysis. Additionally, identifying missing values helps you understand data quality and decide the best strategy for handling gaps based on the context of your problem. Overall, managing missing data is a crucial step for producing valid, trustworthy insights from your datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d31b9",
   "metadata": {},
   "source": [
    "14. What are the benefits of using Plotly for data visualization\n",
    "\n",
    "- Using Plotly for data visualization offers several key benefits:\n",
    "\n",
    "Interactivity: Plotly creates highly interactive charts with built-in features like zooming, panning, hovering tooltips, and clickable legends, making it easy to explore data dynamically.\n",
    "\n",
    "Ease of Use: Plotly’s API is user-friendly and allows quick creation of complex visualizations with minimal code, which is especially helpful for dashboards and web apps.\n",
    "\n",
    "Wide Range of Plot Types: It supports a broad variety of charts, including line, bar, scatter, pie, 3D plots, maps, and specialized statistical plots, covering many use cases.\n",
    "\n",
    "Web Integration: Plotly outputs charts as HTML and JavaScript, making it seamless to embed interactive visualizations into websites, Jupyter notebooks, or dashboards without extra plugins.\n",
    "\n",
    "Cross-platform Compatibility: Plotly works well across different platforms and environments, including Python, R, JavaScript, and more, enabling consistent visualization workflows.\n",
    "\n",
    "Customization: It offers extensive options to customize nearly every aspect of a chart’s appearance and behavior to match branding or presentation needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851397e",
   "metadata": {},
   "source": [
    "15. How does NumPy handle multidimensional array\n",
    "\n",
    "- NumPy handles multidimensional arrays by providing the ndarray object, which can represent arrays of any number of dimensions—1D, 2D, 3D, and beyond. Each dimension is called an axis, and the shape of the array is a tuple that specifies the size along each axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff925ace",
   "metadata": {},
   "source": [
    "16. What is the role of Bokeh in data visualization\n",
    "\n",
    "- Bokeh is a powerful Python library designed for creating interactive and visually appealing data visualizations for modern web browsers. Its main role is to enable users to build rich, customizable plots and dashboards that can be easily embedded into web applications or shared as standalone HTML files.\n",
    "\n",
    "- Unlike static plotting libraries, Bokeh provides interactive features such as zooming, panning, hovering tooltips, and linked brushing, allowing users to explore data dynamically. It is especially useful for building complex dashboards and handling large or streaming datasets with smooth performance.\n",
    "\n",
    "- Bokeh’s design emphasizes flexibility and integration, supporting embedding plots in Jupyter notebooks, standalone HTML documents, or server-backed web apps using Bokeh Server. This makes it a popular choice for data scientists and developers who want to create interactive visualizations that go beyond simple charts, combining ease of use with powerful customization and interactivity options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a0a77",
   "metadata": {},
   "source": [
    "17. Explain the difference between apply() and map() in Pandas\n",
    "\n",
    "In Pandas, both apply() and map() are used to apply functions to data, but they differ in their scope, flexibility, and typical use cases:\n",
    "\n",
    "map() is primarily used with Series to map values element-wise. It is often used to substitute or transform values based on a dictionary, Series, or a function. map() works well for simple value mappings or replacements.\n",
    "\n",
    "apply() is more versatile and can be used with both Series and DataFrames. It allows you to apply a function along an axis (rows or columns in DataFrame) or element-wise in Series. apply() can handle more complex functions, aggregations, or row/column-wise operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbdee08",
   "metadata": {},
   "source": [
    "18. What are some advanced features of NumPy\n",
    "\n",
    "\n",
    "Some advanced features of NumPy that go beyond basic array operations include:\n",
    "\n",
    "Broadcasting: Allows arithmetic operations on arrays of different shapes by automatically expanding the smaller array without making copies, enabling efficient vectorized computations.\n",
    "\n",
    "Fancy Indexing and Boolean Indexing: Lets you select elements using arrays of indices or boolean masks, enabling powerful and flexible data filtering and modification.\n",
    "\n",
    "Structured Arrays and Record Arrays: Support for heterogeneous data types within a single array, similar to a table with named columns, useful for handling complex datasets.\n",
    "\n",
    "Universal Functions (ufuncs): Vectorized functions that operate element-wise on arrays with high performance and support for custom ufuncs.\n",
    "\n",
    "Memory Mapping: Allows working with large datasets stored on disk as if they were in memory, useful for handling big data without loading everything at once.\n",
    "\n",
    "Linear Algebra Module (numpy.linalg): Provides advanced matrix operations like solving linear systems, eigenvalue decomposition, singular value decomposition, and matrix inverses.\n",
    "\n",
    "Random Number Generation: A flexible and extensible random number generator system with support for many probability distributions.\n",
    "\n",
    "FFT (Fast Fourier Transform): Efficient computation of discrete Fourier transforms and inverse transforms for signal processing tasks.\n",
    "\n",
    "Masked Arrays: Support for arrays with missing or invalid entries, allowing computations that ignore masked data.\n",
    "\n",
    "Integration with C/C++ and Fortran: NumPy arrays can be efficiently shared with code written in lower-level languages, facilitating high-performance computing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a421e86",
   "metadata": {},
   "source": [
    "19. How does Pandas simplify time series analysis\n",
    "\n",
    "- Pandas simplifies time series analysis by providing powerful, easy-to-use tools tailored for working with date and time data. It offers specialized data structures like DatetimeIndex, Timestamp, and Timedelta that make handling time-related data intuitive. With Pandas, you can effortlessly parse dates, resample data at different frequencies (e.g., daily to monthly), and perform time-based indexing and slicing.\n",
    "\n",
    "- Additionally, Pandas supports rolling windows, shifts, and time zone conversions, which are essential for analyzing trends, seasonality, and lag effects in time series. Built-in functions for date offsets, periods, and frequency conversion allow easy manipulation and alignment of time series data. Overall, Pandas streamlines many complex operations required for time series analysis, enabling faster and more accurate insights without needing extensive manual handling of date-time details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a12a8",
   "metadata": {},
   "source": [
    "20. What is the role of a pivot table in Pandas\n",
    "\n",
    "\n",
    "- A pivot table in Pandas plays the role of summarizing and reorganizing data to provide insightful, aggregated views. It allows you to reshape large datasets by grouping data based on one or more keys (like categories or time periods), and then computing aggregate statistics such as sum, mean, count, or other functions for each group.\n",
    "\n",
    "- Pivot tables help transform raw data into a more readable and meaningful format, making it easier to analyze patterns, trends, and relationships. They are especially useful for quick exploratory data analysis and reporting, enabling users to compare subsets of data across multiple dimensions (rows and columns) in a compact table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5e44e",
   "metadata": {},
   "source": [
    "21. Why is NumPy’s array slicing faster than Python’s list slicing\n",
    "- NumPy slicing is faster because it operates on fixed-type, contiguous memory blocks and creates views instead of copies, minimizing overhead compared to Python lists that handle more complex, scattered object references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d31a4e",
   "metadata": {},
   "source": [
    "22. What are some common use cases for Seaborn\n",
    "- Some common use cases for Seaborn include:\n",
    "\n",
    "Exploratory Data Analysis (EDA):\n",
    "Quickly visualizing distributions, relationships, and patterns in data with plots like histograms, box plots, and scatter plots.\n",
    "\n",
    "Statistical Visualization:\n",
    "Creating plots that show statistical relationships such as regression lines, confidence intervals, and categorical comparisons using tools like lmplot(), boxplot(), and violinplot().\n",
    "\n",
    "Visualizing Categorical Data:\n",
    "Easily comparing categories with count plots, bar plots, and swarm plots to understand group differences and distributions.\n",
    "\n",
    "Correlation and Heatmaps:\n",
    "Displaying correlation matrices or other pairwise relationships through heatmaps, helping identify strong or weak associations between variables.\n",
    "\n",
    "Multivariate Analysis:\n",
    "Using pair plots and joint plots to visualize interactions among multiple variables in one comprehensive view.\n",
    "\n",
    "Enhanced Aesthetics and Themes:\n",
    "Generating publication-quality graphics with appealing default styles, color palettes, and themes that improve readability and presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70481062",
   "metadata": {},
   "source": [
    "# practical questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526852ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. A How do you create a 2D NumPy array and calculate the sum of each row\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "\n",
    "row_sums = arr.sum(axis=1)\n",
    "\n",
    "print(\"Sum of each row:\", row_sums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Write a Pandas script to find the mean of a specific column in a DataFrameA\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'A': [10, 20, 30, 40],\n",
    "    'B': [5, 15, 25, 35]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the mean of column 'A'\n",
    "mean_value = df['A'].mean()\n",
    "\n",
    "print(\"Mean of column A:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e68d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Create a scatter plot using Matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [5, 7, 4, 6, 8]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(x, y, color='blue', marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Sample Scatter Plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [5, 4, 3, 2, 1],\n",
    "    'C': [2, 3, 4, 5, 6],\n",
    "    'D': [5, 6, 7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "\n",
    "# Show plot\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec74359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.A Generate a bar plot using Plotly\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample data\n",
    "categories = ['Apples', 'Bananas', 'Cherries', 'Dates']\n",
    "values = [10, 15, 7, 12]\n",
    "\n",
    "# Create bar plot\n",
    "fig = go.Figure(data=[go.Bar(x=categories, y=values)])\n",
    "\n",
    "# Add title and axis labels\n",
    "fig.update_layout(\n",
    "    title='Fruit Count',\n",
    "    xaxis_title='Fruit',\n",
    "    yaxis_title='Count'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e05ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Create a DataFrame and add a new column based on an existing column\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Price': [100, 200, 300, 400]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add a new column 'Discounted_Price' which is 10% less than 'Price'\n",
    "df['Discounted_Price'] = df['Price'] * 0.9\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e39a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.Write a program to perform element-wise multiplication of two NumPy arrays\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define two NumPy arrays\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([5, 6, 7, 8])\n",
    "\n",
    "# Element-wise multiplication\n",
    "result = arr1 * arr2\n",
    "\n",
    "print(\"Result of element-wise multiplication:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73319a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Create a line plot with multiple lines using Matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y1 = [2, 3, 5, 7, 11]\n",
    "y2 = [1, 4, 6, 8, 10]\n",
    "\n",
    "# Plot multiple lines\n",
    "plt.plot(x, y1, label='Line 1', color='blue', marker='o')\n",
    "plt.plot(x, y2, label='Line 2', color='red', marker='x')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Multiple Line Plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Score': [85, 90, 75, 88]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define threshold\n",
    "threshold = 30\n",
    "\n",
    "# Filter rows where 'Age' is greater than threshold\n",
    "filtered_df = df[df['Age'] > threshold]\n",
    "\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0be710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Create a histogram using Seaborn to visualize a distributionA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = [12, 15, 14, 16, 18, 20, 21, 19, 22, 23, 20, 18, 17, 15, 14]\n",
    "\n",
    "# Create histogram\n",
    "sns.histplot(data, bins=5, kde=False, color='skyblue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Histogram of Sample Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.Perform matrix multiplication using NumPy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define two matrices\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "\n",
    "# Perform matrix multiplication\n",
    "result = np.matmul(A, B)\n",
    "# Alternatively, you can use: result = A @ B\n",
    "\n",
    "print(\"Result of matrix multiplication:\\n\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.A Use Pandas to load a CSV file and display its first 5 rows\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV file into a DataFrame\n",
    "df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. A Create a 3D scatter plot using Plotly.\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [5, 6, 7, 8, 9]\n",
    "z = [9, 8, 7, 6, 5]\n",
    "\n",
    "# Create 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=z,               # Color by z value\n",
    "        colorscale='Viridis',  # Colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Set plot title and axis labels\n",
    "fig.update_layout(\n",
    "    title='3D Scatter Plot',\n",
    "    scene=dict(\n",
    "        xaxis_title='X Axis',\n",
    "        yaxis_title='Y Axis',\n",
    "        zaxis_title='Z Axis'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
